---
title: "coxkl: Cox Models with KL Divergence for Survival Data Integration"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{coxkl Introduction}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options:
  markdown:
    wrap: sentence
# bibliography: references.bib
---

## Introduction:

Prognosis prediction is a crucial aspect of survival analysis.
In recent years, the surge of biobank data encompassing diverse high-dimensional risk factors such as genetics, transcriptomics, and electronic health records has opened new avenues for advancing prognosis prediction.
Despite this potential, risk prediction for biobank data faces challenges such as limited effective sample sizes, high dimensionality, low signal-to-noise ratios, and patient privacy concerns.

Integrating external information is expected to enhance prediction performance.
However, a key issue with classical integration approaches is the assumption of similar underlying distributions across multiple data sources, which often is not the case.
Overlooking the heterogeneity among different information sources can introduce significant bias.
Consequently, it is crucial to develop a transfer learning procedure that effectively measures the differences between these populations.

Although Kullback-Leibler (KL) divergence has been proposed to integrate external predicted probabilities for binary outcomes, such approaches are not directly applicable to censored time-to-event data due to the complexities of censoring and the typical format of external survival information (e.g., risk scores or coefficients lacking baseline hazard).

To address these issues, the `coxkl` R package provides a transfer learning-based framework for efficient survival data integration, leveraging external information alongside newly collected time-to-event data.
This package offers several key features:

Privacy-Preserving: Requires less sensitive summary statistics (like risk scores or coefficient estimates) from external sources, with no need for individual-level external data.
Robust & Flexible: Handles potential heterogeneity between data sources and supports various formats of external information (coefficients, risk scores, potentially clinical risk groups - check if ranking is implemented).
Adaptive Weighting: Uses tuning parameters (eta) to control the relative weight of external information, prioritizing compatible sources.
High-Dimensionality Support: Implements regularized methods (Ridge, LASSO, Elastic Net via `coxkl_highdim`) to handle datasets where the number of predictors exceeds the number of observations.
Partial Information Handling: Accommodates scenarios where external studies provide information on only a subset of predictors available in the internal study.
This vignette provides an introduction to the `coxkl` package and demonstrates its core functionalities.

## Installation:

You can install the development version of `coxkl` from GitHub using remotes:

```{r, eval=FALSE}
require("devtools")
require("remotes")
remotes::install_github("UM-KevinHe/coxkll", ref = "main")
```

## Quick Start

This section provides a brief overview of the main functions using example data included with the package.

First, load the `coxkl` package:

```{r}
library(coxkll)
```

### Low-Dimensional Integration (`coxkl`)

The `coxkl` function is designed for standard settings where the number of predictors is not substantially larger than the sample size.
It integrates external information provided either as coefficient estimates (beta) or as pre-calculated risk scores (RS).

Let's load some example data.
Assume ExampleData contains covariates z, event status status, survival time time, and externally derived coefficients beta_external.

```{r}
# Load example data (Ensure this data is available in your package)
data("ExampleData")
z <- ExampleData$z
delta <- ExampleData$status
time <- ExampleData$time
beta_ext <- ExampleData$beta_external

# Check dimensions
dim(z)
length(delta)
length(time)
length(beta_ext)
```

### Example 1: Integrating external coefficients (`beta`)

We provide the external coefficients via the beta argument and specify a sequence of tuning parameters eta_list.

```{r}
eta_values <- seq(0, 5, by = 1) # Example sequence for eta

fit_beta <- coxkl(z = z,
                  delta = delta,
                  time = time,
                  beta = beta_ext,
                  eta_list = eta_values)

# Results are stored in lists corresponding to eta_list
# Coefficients for the first eta value (eta=0, standard Cox):
print(head(fit_beta$beta_list[[1]]))

# Linear predictors for the third eta value (eta=2):
print(head(fit_beta$LP_list[[3]]))

# The eta values used:
print(fit_beta$eta_list)
```

When `eta` = 0, `coxkl` fits a standard Cox model without external information.
As `eta` increases, the resulting coefficients are increasingly influenced by the provided `beta_ext`.

### Example 2: Integrating external risk scores (`RS`)

Alternatively, we can provide pre-calculated risk scores.
Let's calculate them using the external beta for this example.

```{r}
# Calculate Risk Score (ensure matrix operations are correct)
rs_ext <- as.matrix(z) %*% as.matrix(beta_ext)

fit_rs <- coxkl(z = z,
                delta = delta,
                time = time,
                RS = rs_ext, # Provide RS instead of beta
                eta_list = eta_values)

# Coefficients for the highest eta value (eta=5):
print(head(fit_rs$beta_list[[length(eta_values)]]))
```

The `coxkl` function adapts its internal KL divergence calculation based on whether `beta` or `RS` is provided.

(Note: You would typically use cross-validation, potentially via `cv.coxkl`, to select the optimal eta value based on prediction performance on held-out data.)

### High-Dimensional Integration (coxkl_highdim)

For datasets with many predictors ($p > n$), the `coxkl_highdim` function combines KL integration with regularization (Lasso, Ridge, or Elastic Net).

Let's assume `ExampleDataHighDim` provides high-dimensional data (`z`, `status`, `time`).
We'll use the previously calculated `rs_ext` as the external information source.

```{r, eval=FALSE}
# data("ExampleDataHighDim") # If you have separate high-dim data

# Using the low-dim data structure for demonstration:
z_highdim <- ExampleData$z
delta_highdim <- ExampleData$status
time_highdim <- ExampleData$time
# rs_ext calculated earlier

# Fit high-dimensional model with Lasso penalty (alpha=1)
fit_highdim <- coxkl_highdim(z = z_highdim,
                             delta = delta_highdim,
                             time = time_highdim,
                             RS = rs_ext, # Provide Risk Score
                             eta_list = 1, # Single eta value for high-dim KL weight
                             alpha = 1,    # Lasso penalty
                             nlambda = 50) # Number of lambda values for regularization path
```

## Real‑World Example: SUPPORT Clinical Data

To illustrate a complete workflow we use the SUPPORT study contained in the survival package.
We treat the large “external” cohort as historical information and a small “internal” cohort as current data to be augmented.

```{r}
# Load SUPPORT data and select patients with metastatic cancer
set.seed(123)

support <- support[support$ca %in% c("metastatic"),]
time <- support$d.time
death <- support$death
diabetes <-  model.matrix(~factor(support$diabetes))[,-1]
#sex: female as the reference group
sex <- model.matrix(~support$sex)[,-1]
#age: continuous variable
age <-support$age
age[support$age<=50] <- "<50"
age[support$age>50 & support$age<=60] <- "50-59"
age[support$age>60 & support$age<70] <- "60-69"
age[support$age>=70] <- "70+"
age <- factor(age, levels = c("60-69", "<50", "50-59", "70+"))
z_age <- model.matrix(~age)[,-1]
z <- data.frame(z_age, sex, diabetes)
colnames(z) <- c("age_50", "age_50_59", "age_70", "diabetes", "male")
data <- data.frame(time, death, z)


n <- nrow(data)
n_ext  <- floor(0.87 * n)
n_int  <- floor(0.03 * n)
n_test <- n - n_ext - n_int
idx     <- sample(seq_len(n))
idx_ext <- idx[       1:n_ext]
idx_int <- idx[(n_ext + 1):(n_ext + n_int)]
idx_test<- idx[(n_ext + n_int + 1):n]

external_data <- data[idx_ext, ]
internal_data <- data[idx_int, ]
test_data     <- data[idx_test, ]

library(survival)
ext_cox <- coxph(
  Surv(time, death) ~ age_50 + age_50_59 + age_70 + diabetes + male,
  data = external_data
)
beta_external <- coef(ext_cox)

result1 <-  coxkl(
  z        = internal_data[, c("age_50", "age_50_59", "age_70", "diabetes", "male")],
  delta    = internal_data$death,
  time     = internal_data$time,
  beta     = beta_external,
  eta_list = seq(0, 5, by = 1)
)

pred <- predict(result1,
                newz = test_data[, c("age_50", "age_50_59", "age_70", "diabetes", "male")],
                delta = test_data$death,
                time  = test_data$time)
```

Use `plot` function to visualize the results:

```{r, fig =TRUE, fig.width=7, fig.height=5}

# Plot improvement across eta values
plot(pred)
```

The figure shows how incorporating external coefficients with a moderate KL weight ($\eta$) can improve the partial likelihood on unseen data.
When eta = 0 the model reduces to the standard Cox fit on the tiny internal set; as eta grows the external information dominates.
The optimal eta balances these sources, typically selected via cross‑validation (`cv.coxkl`).
